{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import math\n",
    "import copy, random\n",
    "inf = math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round1(x):\n",
    "    return round(x, 1)\n",
    "# Evaluates policy by solving linear equations\n",
    "def policy_eval_linear(pi, discount, result):\n",
    "    n = len(pi)\n",
    "    A = np.zeros([n, n]) #co-ffciant Matrix\n",
    "    C = np.zeros(n) #constant matrix\n",
    "    actions = pi[0].keys()\n",
    "    #iterating over all states\n",
    "    for cur in range(n):\n",
    "        A[cur, cur] -= 1\n",
    "        c = 0\n",
    "        for a in actions:\n",
    "            probs = result(cur, a) #returns a list of possibilities with thier probabilities\n",
    "            for prob, r, s in probs:\n",
    "                c -= prob * r * pi[cur][a]\n",
    "                A[cur, s] += prob * pi[cur][a] * discount \n",
    "        C[cur] = c        \n",
    "    V = np.linalg.solve(A, C)    \n",
    "    eps = 1e-10\n",
    "    return V\n",
    "\n",
    "#Utility Function to print a single, array into a 2-d array, with col-size = n\n",
    "def print_grid(arr, n):\n",
    "    m = n \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            print(arr[i*m + j], end = ', ')\n",
    "        print()\n",
    "\n",
    "\n",
    "def policy_improv(pi, v, discount, result):\n",
    "    n = len(pi) #number of states\n",
    "    actions = pi[0].keys()\n",
    "    default = {} #utility data member: used to initialize the policy of each action with all zeros.\n",
    "    states = pi.keys()\n",
    "    for a in actions:\n",
    "        default[a] = 0\n",
    "    for i in states:\n",
    "        best = [-inf, '0']\n",
    "        for a in actions:\n",
    "            probs = result(i, a) #returns a list of possiblities with >0 probability\n",
    "            qi = 0\n",
    "            for prob, r, state in probs:\n",
    "                qi += prob*(r + discount*v[state])\n",
    "            best = max(best, [qi, a])\n",
    "        pi[i] = default.copy()\n",
    "        pi[i][best[1]] = 1    \n",
    "    return pi\n",
    "\n",
    "\n",
    "def policy_eval(pi, discount, result):\n",
    "    n = len(pi)\n",
    "    actions = pi[0].keys()\n",
    "    v = np.zeros(n)\n",
    "    old_v = np.zeros(n)\n",
    "    states = pi.keys()\n",
    "    delta = 1e-3\n",
    "    diff = 1000\n",
    "    while(diff > delta):\n",
    "        diff = 0\n",
    "        old_v = copy.deepcopy(v) \n",
    "        for i in states:\n",
    "            vi  = 0\n",
    "            for a in actions:\n",
    "                probs = result(i, a)\n",
    "                for prob, r, state in probs:\n",
    "                    vi += pi[i][a]*prob*(r + discount*old_v[state])\n",
    "              \n",
    "            v[i] = vi\n",
    "            diff = max(diff, abs(v[i] - old_v[i]))\n",
    "    return v\n",
    "                \n",
    "    \n",
    "def policy_iter(pi, discount, result, lin = True):\n",
    "    log = []\n",
    "    old_v = np.array([])\n",
    "    flag = True\n",
    "    eps = 1e-10\n",
    "    \n",
    "    #Choice between solving using linear equations and policy method\n",
    "    if(lin):\n",
    "        v = policy_eval_linear(pi, discount, result)\n",
    "    else:\n",
    "        \n",
    "        v = policy_eval(pi, discount, result)\n",
    "    pi = policy_improv(pi, v, discount, result)\n",
    "    \n",
    "    \n",
    "    while(flag or (old_v != v).any()):\n",
    "        old_v = v\n",
    "        flag = False\n",
    "        if(lin):\n",
    "            v = policy_eval_linear(pi, discount, result)\n",
    "        else:\n",
    "            v = policy_eval(pi, discount, result)\n",
    "        pi = policy_improv(pi, v, discount, result)\n",
    "        v = np.array(list(map(round1, v)))\n",
    "        opt = {}\n",
    "        for i in pi:\n",
    "            for j in pi[i]:\n",
    "                if(pi[i][j] > 1 - eps):\n",
    "                    opt[i] = j\n",
    "        log.append((copy.deepcopy(v), copy.deepcopy(opt)))\n",
    "    return pi, log\n",
    "        \n",
    "def value_iter(pi, discount, result):\n",
    "    log = []\n",
    "    delta = 1e-3\n",
    "    diff = 1000\n",
    "    actions = pi[0].keys()\n",
    "    n = len(pi)\n",
    "    old_v = []\n",
    "    v = np.zeros(n)\n",
    "    default = {}\n",
    "    states = pi.keys()\n",
    "    opt = {}\n",
    "\n",
    "    for a in actions:\n",
    "        default[a] = 0\n",
    "    while(diff > delta):\n",
    "        diff = 0\n",
    "        old_v = v.copy()\n",
    "        for i in states:\n",
    "            best = [-math.inf,'0']\n",
    "            for a in actions:\n",
    "                probs = result(i, a)\n",
    "                qi = 0\n",
    "                for prob, r, state in probs:\n",
    "                    qi += prob * (r + discount*old_v[state])\n",
    "                best = max(best, [qi, a])\n",
    "            v[i] = best[0]\n",
    "            opt[i] = best[1]\n",
    "            \n",
    "            diff = max(diff, abs(old_v[i] - v[i]))\n",
    "        log.append((copy.deepcopy(v), copy.deepcopy(opt)))\n",
    "    for i in states:\n",
    "        best = [-inf, '0']\n",
    "        for a in actions:            \n",
    "            probs = result(i, a)\n",
    "            qi = 0\n",
    "            for prob, r, s in probs:\n",
    "                \n",
    "                qi += prob * (r + discount*v[s])\n",
    "            best = max(best, [qi, a])\n",
    "        pi[i] = default.copy()\n",
    "        pi[i][best[1]] = 1\n",
    "    return pi, log\n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2, 4\n",
    "##Driver and Utility of function\n",
    "##Also Has the MDP in the form of result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value Function as solved by Linear Equations\n",
      "3.3, 8.8, 4.4, 5.3, 1.5, \n",
      "1.5, 3.0, 2.3, 1.9, 0.5, \n",
      "0.1, 0.7, 0.7, 0.4, -0.4, \n",
      "-1.0, -0.4, -0.4, -0.6, -1.2, \n",
      "-1.9, -1.3, -1.2, -1.4, -2.0, \n",
      "Optimal Policy\n",
      "r, u, l, u, l, \n",
      "u, u, u, l, l, \n",
      "u, u, u, u, u, \n",
      "u, u, u, u, u, \n",
      "u, u, u, u, l, \n",
      "value Function\n",
      "22.0, 24.4, 22.0, 19.4, 17.5, \n",
      "19.8, 22.0, 19.8, 17.8, 16.0, \n",
      "17.8, 19.8, 17.8, 16.0, 14.4, \n",
      "16.0, 17.8, 16.0, 14.4, 13.0, \n",
      "14.4, 16.0, 14.4, 13.0, 11.7, \n"
     ]
    }
   ],
   "source": [
    "def result(state, a):\n",
    "    n = 5\n",
    "    srca, desta, srcb, destb = 1, 21, 3, 13\n",
    "    if(state == srca):\n",
    "        return [(1, 10, desta)]\n",
    "    if(state == srcb):\n",
    "        return [(1, 5, destb)]\n",
    "    if(a == 'l'):\n",
    "        return left(state, n)\n",
    "    elif(a == 'r'):\n",
    "        return right(state, n)\n",
    "    elif(a == 'u'):\n",
    "        return up(state, n)\n",
    "    else:\n",
    "        return down(state, n)\n",
    "    \n",
    "def up(state, n): #returns (r, s)\n",
    "    i = state // n\n",
    "    j  = state % n\n",
    "    if(i > 0): \n",
    "        return [(1,0, state - n)] \n",
    "    else:\n",
    "        return [(1,-1, state)]\n",
    "    \n",
    "def left(state, n): #returns (r, s)\n",
    "    i = state // n\n",
    "    j  = state % n\n",
    "    if(j > 0): \n",
    "        return [(1,0, state - 1)]\n",
    "    else:\n",
    "        return [(1,-1, state)]\n",
    "    \n",
    "def down(state, n): #returns (r, s)\n",
    "    i = state // n\n",
    "    j  = state % n\n",
    "    if(i < n - 1): \n",
    "        return [(1,0, state + n)] \n",
    "    else:\n",
    "        return [(1,-1, state)]\n",
    "    \n",
    "def right(state, n): #returns (r, s)\n",
    "    i = state // n\n",
    "    j  = state % n\n",
    "    if(j < n - 1): \n",
    "        return [(1,0, state + 1)] \n",
    "    else:\n",
    "        return [(1,-1, state)]\n",
    "def round1(x):\n",
    "    return round(x, 1)\n",
    "\n",
    "def q2():\n",
    "    n = 5\n",
    "    deci = {\"l\":0.25, \"r\":0.25, \"u\":0.25, \"d\":0.25}\n",
    "    pi = []\n",
    "    for i in range(n*n):\n",
    "        pi.append(deci)\n",
    "    v = policy_eval_linear(pi, 0.9, result)\n",
    "    v = list(map(round1, v))\n",
    "    print(\"value Function as solved by Linear Equations\")\n",
    "    print_grid(v, n)\n",
    "    \n",
    "def q4():\n",
    "    n = 5\n",
    "    deci = {\"l\":0.25, \"r\":0.25, \"u\":0.25, \"d\":0.25}\n",
    "    pi = {}\n",
    "    for i in range(n*n):\n",
    "        pi[i] = copy.deepcopy(deci)\n",
    "    \n",
    "    pi_star, log = policy_iter(pi, 0.9, result)\n",
    "    to_print = []\n",
    "    #Simplifing the entire policy to just the best action for clearer display\n",
    "    for i in pi_star:\n",
    "        i = pi_star[i]\n",
    "        best = (-1, -1)\n",
    "        for j in deci.keys():\n",
    "            best = max(best, (i[j], j))\n",
    "        to_print.append(best[1])\n",
    "    print(\"Optimal Policy\")\n",
    "    print_grid(to_print, n)\n",
    "    v = policy_eval_linear(pi, 0.9, result)\n",
    "    v = list(map(round1, v))\n",
    "    print(\"value Function\")\n",
    "    print_grid(v, n)\n",
    "q2()\n",
    "q4()        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6\n",
    "##Driver and Utility of function\n",
    "##Also Has the MDP in the form of result function\n",
    "##Bug is fixed by changing the check of the equality, since it is possible for 2 optimum policies to exisit, but the optimum value function is uniuqe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some samples from log\n",
      "0.0, -1.0, -2.0, -3.0, \n",
      "-1.0, -2.0, -3.0, -2.0, \n",
      "-2.0, -3.0, -2.0, -1.0, \n",
      "-3.0, -2.0, -1.0, 0.0, \n",
      "u, l, l, l, \n",
      "u, u, u, d, \n",
      "u, u, r, d, \n",
      "u, r, r, u, \n",
      "\n",
      "0.0, -1.0, -2.0, -3.0, \n",
      "-1.0, -2.0, -3.0, -2.0, \n",
      "-2.0, -3.0, -2.0, -1.0, \n",
      "-3.0, -2.0, -1.0, 0.0, \n",
      "u, l, l, l, \n",
      "u, u, u, d, \n",
      "u, u, r, d, \n",
      "u, r, r, u, \n",
      "\n",
      "An optimal Policy using Policy Iteration\n",
      "u, l, l, l, \n",
      "u, u, u, d, \n",
      "u, u, r, d, \n",
      "u, r, r, u, \n",
      "Corresponding value function\n",
      "0.0, -1.0, -2.0, -3.0, \n",
      "-1.0, -2.0, -3.0, -2.0, \n",
      "-2.0, -3.0, -2.0, -1.0, \n",
      "-3.0, -2.0, -1.0, 0.0, \n",
      "some samples from log\n",
      "0.0, -1.0, -2.0, -2.0, \n",
      "-1.0, -2.0, -2.0, -2.0, \n",
      "-2.0, -2.0, -2.0, -1.0, \n",
      "-2.0, -2.0, -1.0, 0.0, \n",
      "u, l, u, u, \n",
      "u, u, u, u, \n",
      "u, u, u, d, \n",
      "u, u, r, u, \n",
      "\n",
      "0.0, -1.0, -2.0, -2.0, \n",
      "-1.0, -2.0, -2.0, -2.0, \n",
      "-2.0, -2.0, -2.0, -1.0, \n",
      "-2.0, -2.0, -1.0, 0.0, \n",
      "u, l, u, u, \n",
      "u, u, u, u, \n",
      "u, u, u, d, \n",
      "u, u, r, u, \n",
      "\n",
      "0.0, -1.0, -2.0, -3.0, \n",
      "-1.0, -2.0, -3.0, -2.0, \n",
      "-2.0, -3.0, -2.0, -1.0, \n",
      "-3.0, -2.0, -1.0, 0.0, \n",
      "u, l, l, l, \n",
      "u, u, u, d, \n",
      "u, u, r, d, \n",
      "u, r, r, u, \n",
      "\n",
      "An optimal policy using Value Iteration\n",
      "u, l, l, l, \n",
      "u, u, u, d, \n",
      "u, u, r, d, \n",
      "u, r, r, u, \n",
      "Corresponding Value function\n",
      "0.0, -1.0, -2.0, -3.0, \n",
      "-1.0, -2.0, -3.0, -2.0, \n",
      "-2.0, -3.0, -2.0, -1.0, \n",
      "-3.0, -2.0, -1.0, 0.0, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def result_helper_q6(state, a):\n",
    "    n = 4\n",
    "    if(a == 'l'):\n",
    "        return left(state, n)\n",
    "    elif(a == 'r'):\n",
    "        return right(state, n)\n",
    "    elif(a == 'u'):\n",
    "        return up(state, n)\n",
    "    else:\n",
    "        return down(state, n)\n",
    "def print_log(log):\n",
    "    print(\"some samples from log\")\n",
    "    if(len(log) < 3):\n",
    "        for i in log:\n",
    "            print_grid(i[0],4)\n",
    "            print_grid(i[1],4)\n",
    "            print()\n",
    "    else:\n",
    "        index = []\n",
    "        for i in range(3):\n",
    "            index.append(random.randint(0, len(log) - 1))\n",
    "        index.sort()\n",
    "        for i in index:\n",
    "            i = log[i]\n",
    "            print_grid(i[0],4)\n",
    "            print_grid(i[1],4)\n",
    "            print()\n",
    "\n",
    "def result_q6(state, a):\n",
    "    if(state in [0, 15]):\n",
    "        return [(1,0, 0)]\n",
    "    p,waste, state = result_helper_q6(state, a)[0]\n",
    "    if(state in [0, 15]):\n",
    "        return [(1,-1, 0)]\n",
    "    return [(1,-1, state)]\n",
    "\n",
    "def q6():\n",
    "    n = 4\n",
    "    deci = {\"l\":0.25, \"r\":0.25, \"u\":0.25, \"d\":0.25}\n",
    "    pi = {}\n",
    "    for i in range(n*n):#creating initial policy\n",
    "        pi[i] = copy.deepcopy(deci)\n",
    "    pi_star, log = policy_iter(pi, 1, result_q6, False)\n",
    "    to_print = []\n",
    "    print_log(log)\n",
    "    #Simplifing the entire policy to just the best action for clearer display\n",
    "    for i in pi_star:\n",
    "        i = pi_star[i]\n",
    "        best = (-1, -1)\n",
    "        for j in deci.keys():\n",
    "            best = max(best, (i[j], j))\n",
    "        to_print.append(best[1])\n",
    "    print(\"An optimal Policy using Policy Iteration\")\n",
    "    print_grid(to_print, n)\n",
    "    v = policy_eval(pi_star, 1, result_q6)\n",
    "    v = list(map(round1, v))\n",
    "    print(\"Corresponding value function\")\n",
    "    print_grid(v, n)\n",
    "    pi = {}\n",
    "    for i in range(n*n):#creating initial policy\n",
    "        pi[i] = copy.deepcopy(deci)\n",
    "    pi_star2, log2 = value_iter(pi,1, result_q6)\n",
    "    print_log(log2)\n",
    "    to_print = [] \n",
    "    #Simplifing the entire policy to just the best action for clearer display\n",
    "    for i in pi_star2:\n",
    "        i = pi_star2[i]\n",
    "        best = (-1, -1)\n",
    "        for j in deci.keys():\n",
    "            best = max(best, (i[j], j))\n",
    "        to_print.append(best[1])\n",
    "    print(\"An optimal policy using Value Iteration\")\n",
    "    print_grid(to_print, n)\n",
    "\n",
    "    v = policy_eval(pi_star2, 1, result_q6)\n",
    "    v = list(map(round1, v))\n",
    "    print(\"Corresponding Value function\")\n",
    "    print_grid(v, n)\n",
    "    print()\n",
    "    \n",
    "q6()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-218-fe0952261253>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-218-fe0952261253>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def poisson_prob(lam, n):\n",
    "    return (pow(lam, n)/math.factorial(n))*math.exp(-lam)\n",
    "    \n",
    "\n",
    "def result(s,a):\n",
    "    \n",
    "    ans = {}\n",
    "    for i in range(20):\n",
    "        probi = poisson_prob(3,i)\n",
    "        for j in range(20):\n",
    "            probj = poisson_prob(4, j)\n",
    "            r = min(s[0], i) + min(s[1], j)\n",
    "            r *= 10\n",
    "            \n",
    "            \n",
    "            curx, cury = max(s[0] - i, 0), max(s[1] - j, 0)\n",
    "            for retx in range(20):\n",
    "                proby = poisson_prob(3, retx)\n",
    "                for rety in range(20):\n",
    "                    proby = poisson_prob(2, rety)\n",
    "                    finx = min(20, minx + retx)\n",
    "                    finy = min(20, miny + rety)\n",
    "                    if((finx, finy) not in ans):\n",
    "                            ans[(finx, finy)] = [0, 0]\n",
    "                    ans[(finx, finy)][0] += probi*probj*probx*proby\n",
    "                    ans[(finx, finy)][1] += r * probi*probj*probx*proby\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    for i in range(20):\n",
    "        probi = poisson_prob(3,i)\n",
    "        for j in range(20):\n",
    "            probj = poisson_prob(2, i)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "                \n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
